{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('Data\\\\names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xtest, Ytest = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn(27,2, generator=g)\n",
    "W1 = torch.randn(6,100, generator=g)\n",
    "b1=torch.randn(100, generator=g)\n",
    "W2 = torch.randn(100, 27, generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [W1, b1, W2, b2, C]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum =0\n",
    "for p in parameters:\n",
    "    sum+=p.nelement()\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(36.6747, grad_fn=<NllLossBackward0>)\n",
      "tensor(35.4981, grad_fn=<NllLossBackward0>)\n",
      "tensor(34.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(33.3336, grad_fn=<NllLossBackward0>)\n",
      "tensor(32.3347, grad_fn=<NllLossBackward0>)\n",
      "tensor(31.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(30.4920, grad_fn=<NllLossBackward0>)\n",
      "tensor(29.6473, grad_fn=<NllLossBackward0>)\n",
      "tensor(28.8551, grad_fn=<NllLossBackward0>)\n",
      "tensor(28.1162, grad_fn=<NllLossBackward0>)\n",
      "tensor(27.4279, grad_fn=<NllLossBackward0>)\n",
      "tensor(26.7836, grad_fn=<NllLossBackward0>)\n",
      "tensor(26.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(25.5953, grad_fn=<NllLossBackward0>)\n",
      "tensor(25.0409, grad_fn=<NllLossBackward0>)\n",
      "tensor(24.5092, grad_fn=<NllLossBackward0>)\n",
      "tensor(23.9984, grad_fn=<NllLossBackward0>)\n",
      "tensor(23.5073, grad_fn=<NllLossBackward0>)\n",
      "tensor(23.0350, grad_fn=<NllLossBackward0>)\n",
      "tensor(22.5812, grad_fn=<NllLossBackward0>)\n",
      "tensor(22.1460, grad_fn=<NllLossBackward0>)\n",
      "tensor(21.7296, grad_fn=<NllLossBackward0>)\n",
      "tensor(21.3318, grad_fn=<NllLossBackward0>)\n",
      "tensor(20.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(20.5879, grad_fn=<NllLossBackward0>)\n",
      "tensor(20.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(19.9009, grad_fn=<NllLossBackward0>)\n",
      "tensor(19.5752, grad_fn=<NllLossBackward0>)\n",
      "tensor(19.2604, grad_fn=<NllLossBackward0>)\n",
      "tensor(18.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(18.6604, grad_fn=<NllLossBackward0>)\n",
      "tensor(18.3739, grad_fn=<NllLossBackward0>)\n",
      "tensor(18.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(17.8244, grad_fn=<NllLossBackward0>)\n",
      "tensor(17.5607, grad_fn=<NllLossBackward0>)\n",
      "tensor(17.3037, grad_fn=<NllLossBackward0>)\n",
      "tensor(17.0533, grad_fn=<NllLossBackward0>)\n",
      "tensor(16.8091, grad_fn=<NllLossBackward0>)\n",
      "tensor(16.5709, grad_fn=<NllLossBackward0>)\n",
      "tensor(16.3384, grad_fn=<NllLossBackward0>)\n",
      "tensor(16.1114, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.8896, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.6728, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.4608, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.2534, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.8519, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.6574, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.4669, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.2802, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.0974, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.7427, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.5706, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.4019, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.2365, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.7596, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.6068, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.4570, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.3101, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.1660, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.0247, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.8862, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.7503, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.6171, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.4864, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.3582, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.2325, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.1092, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.9883, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.8697, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.7533, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.6392, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.5273, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.4175, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.3098, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.2042, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.1006, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.9990, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8993, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8015, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7057, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6116, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5193, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4288, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3400, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.1673, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.0833, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.8405, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.7625, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6858, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6105, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5365, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4638, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3923, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3221, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2530, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.1851, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.1183, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0526, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9879, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8618, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8003, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.7397, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6801, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6214, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5636, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5068, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3956, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3413, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2352, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1322, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0819, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0323, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9834, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8878, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8411, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7950, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7496, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7048, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6607, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6172, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5744, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5321, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4905, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4494, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4089, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3689, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3296, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2907, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2524, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2147, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1407, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1045, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0688, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0335, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9988, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8973, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8644, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8320, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8000, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7684, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7372, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7065, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6761, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6462, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6167, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5876, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5588, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5305, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5025, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4749, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4477, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4208, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3943, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3682, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3424, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3169, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2918, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2670, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2425, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1945, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1478, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0580, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0149, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9938, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8921, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8726, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8533, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8343, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8155, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7969, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7787, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7606, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7428, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7252, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7078, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6907, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6737, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6570, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6405, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6242, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6082, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5923, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5766, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5612, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5459, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5308, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5159, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5012, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4867, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4724, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4582, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4443, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4305, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4168, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4034, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3901, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3769, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3640, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3512, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3385, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3260, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3137, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3015, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2895, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2776, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2658, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2427, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2314, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2202, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2091, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1982, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1874, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1661, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1557, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1454, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1352, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1054, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0957, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0861, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0766, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0672, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0579, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0219, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9874, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9708, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9004, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8930, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8857, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8785, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8713, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8643, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8573, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8504, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8435, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8368, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8301, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8235, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8169, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8105, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8041, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7978, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7915, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7853, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7792, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7731, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7671, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7612, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7554, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7496, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7438, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7382, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7326, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7270, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7215, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7161, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7107, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7054, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7002, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6950, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6898, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6847, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6797, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6747, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6698, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6649, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6601, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6553, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6506, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6459, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6413, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6367, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6322, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6277, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6233, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6189, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6146, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6061, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6018, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5977, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5936, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5895, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5855, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5815, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5775, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5736, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5697, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5659, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5621, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5584, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5546, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5510, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5473, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5437, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5401, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5366, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5331, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5296, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5262, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5228, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5194, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5161, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5128, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5095, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5063, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5031, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4999, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4968, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4937, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4906, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4875, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4845, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4815, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4786, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4756, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4727, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4698, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4670, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4641, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4613, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4585, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4558, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4530, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4503, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4477, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4450, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4424, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4398, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4346, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4321, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4295, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4271, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4246, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4221, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4197, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4173, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4149, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4125, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4102, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4078, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4055, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4032, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4010, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3987, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3965, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3942, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3920, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3899, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3834, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3813, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3792, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3771, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3751, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3730, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3710, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3690, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3670, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3650, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3630, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3611, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3591, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3572, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3553, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3534, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3515, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3496, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3478, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3459, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3441, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3423, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3405, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3387, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3369, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3352, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3334, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3317, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3299, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3282, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3265, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3248, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3231, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3215, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3182, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3165, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3149, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3133, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3117, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3101, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3085, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3069, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3054, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3038, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3023, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3007, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2992, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2977, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2962, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2947, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2932, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2917, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2902, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2888, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2873, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2830, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2816, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2802, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2788, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2774, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2760, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2746, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2733, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2719, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2692, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2679, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2665, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2639, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2626, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2613, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2600, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2574, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2562, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2549, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2536, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2524, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2499, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2486, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2474, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2462, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2450, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2426, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2366, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2355, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2343, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2308, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2297, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2286, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2274, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2252, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2241, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2219, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2208, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2197, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2186, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2175, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2153, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2143, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2132, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2111, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2100, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2090, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2059, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2048, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2038, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2028, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2018, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2008, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1998, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1988, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1978, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1938, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1918, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1909, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1889, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1880, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1870, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1861, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1851, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1842, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1832, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1813, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1804, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1795, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1786, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1776, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1758, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1740, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1722, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1713, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1695, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1668, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1660, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1642, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1633, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1625, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1616, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1608, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1599, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1590, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1582, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1573, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1565, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1556, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1548, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1540, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1531, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1523, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1506, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1498, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1490, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1482, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1474, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1465, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1457, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1441, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1425, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1417, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1409, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1401, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1393, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1378, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1370, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1362, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1354, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1346, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1339, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1331, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1323, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1315, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1308, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1300, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1292, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1277, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1270, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1262, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1255, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1247, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1240, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1232, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1225, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1203, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1195, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1188, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1181, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1174, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1159, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1145, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1137, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1130, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1116, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1109, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1067, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1039, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1018, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1011, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0998, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0970, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0957, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0944, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0930, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0924, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0917, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0910, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0904, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0897, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0891, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0884, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0871, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0864, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0858, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0852, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0839, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0832, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0826, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0819, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0813, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0807, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0794, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0788, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0781, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0775, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0762, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0756, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0750, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0737, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0731, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0725, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0719, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0713, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0707, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0700, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0694, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0688, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0682, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0676, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0670, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0664, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0658, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0646, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0640, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0634, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0628, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0622, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0616, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0610, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0604, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0598, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0592, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0586, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0580, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0574, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0569, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0563, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0557, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0551, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0545, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0539, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0534, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0528, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0522, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0510, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0499, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0488, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\NNZTH\\testing.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         p\u001b[39m.\u001b[39mdata \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate\u001b[39m*\u001b[39mp\u001b[39m.\u001b[39mgrad\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m (loss)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m training_loop(parameters, Xtr, Ytr)\n",
      "\u001b[1;32me:\\NNZTH\\testing.ipynb Cell 7\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(parameters, X, Y)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m logits \u001b[39m=\u001b[39m h\u001b[39m@W2\u001b[39m \u001b[39m+\u001b[39mb2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(logits, Y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/NNZTH/testing.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     p\u001b[39m.\u001b[39mdata \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate\u001b[39m*\u001b[39mp\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Users\\Aleem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Aleem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Aleem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training_loop(parameters, X,Y):\n",
    "   learning_rate = 1e-2\n",
    "   for i in range(1,1000):\n",
    "    W1, b1, W2, b2, C = parameters\n",
    "    for p in parameters:\n",
    "       p.grad= None\n",
    "    emb = C[X]\n",
    "    h = emb.view(-1, 6) @ W1 + b1\n",
    "    logits = h@W2 +b2\n",
    "    loss = torch.nn.functional.cross_entropy(logits, Y)\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate*p.grad\n",
    "    \n",
    "    print (loss)\n",
    "\n",
    "training_loop(parameters, Xtr, Ytr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55.4190)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
